# ğŸš€ GuÃ­a de Deployment para Render

## ğŸ“‹ Archivos necesarios (ya incluidos):
- âœ… `app.py` - API Flask principal
- âœ… `requirements.txt` - Dependencias
- âœ… `gunicorn_config.py` - ConfiguraciÃ³n de Gunicorn
- âœ… `Procfile` - Comando de inicio (Heroku/Render)
- âœ… `.gitignore` - Archivos a ignorar

---

## ğŸ¯ Pasos para Deploy en Render:

### 1ï¸âƒ£ Sube tu cÃ³digo a GitHub
```bash
git add .
git commit -m "Ready for deployment"
git push origin main
```

### 2ï¸âƒ£ Crea cuenta en Render
- Ve a https://render.com
- RegÃ­strate (gratis)

### 3ï¸âƒ£ Crea un nuevo Web Service
1. Click en "New +" â†’ "Web Service"
2. Conecta tu repositorio de GitHub
3. Selecciona el repo `firo-ia-api`

### 4ï¸âƒ£ ConfiguraciÃ³n del servicio:

**Name:** `firo-ia-api` (o el nombre que quieras)

**Environment:** `Python 3`

**Build Command:**
```bash
pip install -r requirements.txt
```

**Start Command:**
```bash
gunicorn -c gunicorn_config.py app:app
```

### 5ï¸âƒ£ Variables de Entorno (Environment Variables):

En la secciÃ³n "Environment", agrega:

```
METEOMATICS_USER = tu_usuario_aqui
METEOMATICS_PASS = tu_password_aqui
MODEL_PATH = models/fire_prediction_models_complete.pkl
FLASK_ENV = production
PYTHON_VERSION = 3.13.0
```

### 6ï¸âƒ£ Plan:
- Selecciona **"Free"** (gratis)

### 7ï¸âƒ£ Deploy:
- Click en "Create Web Service"
- Render automÃ¡ticamente:
  - âœ… Clona tu repo
  - âœ… Instala dependencias
  - âœ… Inicia tu API con Gunicorn
  - âœ… Te da una URL pÃºblica (ej: `https://firo-ia-api.onrender.com`)

---

## ğŸ§ª Probar tu API deployada:

Una vez que el deploy termine, prueba:

```bash
# Health check
curl https://tu-app.onrender.com/health

# PredicciÃ³n
curl -X POST https://tu-app.onrender.com/predict-fire-risk \
  -H "Content-Type: application/json" \
  -d '{
    "bbox_corners": {
      "top_left": [-14.219889, -71.271138],
      "bottom_right": [-14.306682, -71.176567]
    },
    "forecast_date": "2025-10-06"
  }'
```

---

## âš ï¸ Notas Importantes:

### Limitaciones del Plan Free de Render:
- â° Se duerme despuÃ©s de 15 min sin uso
- â³ Primera peticiÃ³n despuÃ©s de dormir tarda ~1 min
- ğŸ’¾ 750 horas gratis al mes
- ğŸ”„ Auto-deploy al hacer push a GitHub

### Archivos Grandes:
Si el PKL es muy grande (>100 MB):
- Considera usar Git LFS
- O sube el modelo a Google Drive/S3 y descÃ¡rgalo en startup

---

## ğŸ”§ Comandos Ãºtiles de Render:

- **Ver logs:** En el dashboard de Render â†’ Logs
- **Re-deploy manual:** En dashboard â†’ Manual Deploy
- **Variables de entorno:** Settings â†’ Environment

---

## ğŸ‰ Â¡Listo!

Tu API estarÃ¡ disponible en:
```
https://tu-app-name.onrender.com
```

Endpoints:
- GET  https://tu-app-name.onrender.com/health
- GET  https://tu-app-name.onrender.com/model-info
- POST https://tu-app-name.onrender.com/predict-fire-risk
- POST https://tu-app-name.onrender.com/validate-coordinates

---

## ğŸ†˜ Troubleshooting:

**Error: "Application failed to respond"**
- Verifica las variables de entorno
- Revisa los logs en Render

**Error: "ModuleNotFoundError"**
- Verifica que `requirements.txt` estÃ© completo

**API muy lenta en primera peticiÃ³n:**
- Normal en plan free (cold start)
- Considera upgrade a plan de pago si es crÃ­tico

---

## ğŸ“š Alternativas:

Si tienes problemas con Render, tambiÃ©n puedes usar:
- **Railway.app** - Similar a Render
- **Fly.io** - MÃ¡s rÃ¡pido pero requiere CLI
- **PythonAnywhere** - Especializado en Python

---

**Â¡Tu API estÃ¡ lista para producciÃ³n! ğŸš€**
